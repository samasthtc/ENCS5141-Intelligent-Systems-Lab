{"cells":[{"cell_type":"markdown","source":["# [**Jump to Tasks**](#Tasks)"],"metadata":{"id":"51tYSt3rRDMz"}},{"cell_type":"code","source":["!pip install ipython-autotime\n","%load_ext autotime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MwK_GEu8VRCu","executionInfo":{"status":"ok","timestamp":1722975349336,"user_tz":-180,"elapsed":5108,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"f5938ce7-1128-4618-f120-4d4ccf99e674"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.10/dist-packages (0.3.2)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (71.0.4)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.19.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.47)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\n","The autotime extension is already loaded. To reload it, use:\n","  %reload_ext autotime\n","time: 4.94 s (started: 2024-08-06 20:15:43 +00:00)\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np"],"metadata":{"id":"T6fUpVKKQy6A","executionInfo":{"status":"ok","timestamp":1722975349336,"user_tz":-180,"elapsed":34,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fa3241e1-e5f4-46c5-8450-7bef1ce3a58c"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 292 µs (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"markdown","source":["# Tensor Initialization"],"metadata":{"id":"PvM0ihoNRCxY"}},{"cell_type":"markdown","source":["## Directly from data"],"metadata":{"id":"8oTwr-vuRGc4"}},{"cell_type":"code","source":["data = [[1, 2], [3, 4]]\n","x_data = torch.tensor(data)\n","x_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ISa_TfhuRIX0","executionInfo":{"status":"ok","timestamp":1722975349336,"user_tz":-180,"elapsed":29,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"0277da0b-1a52-4b34-90ba-0cee49a1f780"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2],\n","        [3, 4]])"]},"metadata":{},"execution_count":53},{"output_type":"stream","name":"stdout","text":["time: 4.65 ms (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"markdown","source":["## From a numpy array"],"metadata":{"id":"ZKKJAkQ1RLpu"}},{"cell_type":"code","source":["np_array = np.array(data)\n","x_np = torch.from_numpy(np_array)\n","x_np"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"07BZz2cqRNxT","executionInfo":{"status":"ok","timestamp":1722975349336,"user_tz":-180,"elapsed":26,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"ce4d5309-9bfb-4f63-bf4c-50b6bb3874a4"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2],\n","        [3, 4]])"]},"metadata":{},"execution_count":54},{"output_type":"stream","name":"stdout","text":["time: 3.37 ms (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"markdown","source":["## from another tensor"],"metadata":{"id":"AejMEkiLRQ4B"}},{"cell_type":"markdown","source":["- retains porperties of x_data"],"metadata":{"id":"8K1x7WcNRhoI"}},{"cell_type":"code","source":["x_ones = torch.ones_like(x_data)\n","x_ones"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EqMFl5d2RSFt","executionInfo":{"status":"ok","timestamp":1722975349336,"user_tz":-180,"elapsed":24,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"3636bde1-12ab-411b-f44b-59442c177f98"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 1],\n","        [1, 1]])"]},"metadata":{},"execution_count":55},{"output_type":"stream","name":"stdout","text":["time: 4.71 ms (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"markdown","source":["- overrides the datatype of x_data"],"metadata":{"id":"eU7AVNABRkcJ"}},{"cell_type":"code","source":["x_rand = torch.rand_like(x_data, dtype=torch.float)\n","x_rand"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lkc1-Hq_Regp","executionInfo":{"status":"ok","timestamp":1722975349336,"user_tz":-180,"elapsed":22,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"60a6747e-66a2-4581-b86d-b5b6d30232d0"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.7031, 0.0231],\n","        [0.3318, 0.6202]])"]},"metadata":{},"execution_count":56},{"output_type":"stream","name":"stdout","text":["time: 4.62 ms (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"markdown","source":["## With random or constant values"],"metadata":{"id":"Jlk9bw_oRn_Q"}},{"cell_type":"code","source":["shape = (2, 3)\n","rand_tensor = torch.rand(shape)\n","rand_tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dhhAyLDORp14","executionInfo":{"status":"ok","timestamp":1722975349336,"user_tz":-180,"elapsed":21,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"7c9d249d-8a7c-4ab6-ee21-51c07fed66ff"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.6271, 0.2127, 0.5294],\n","        [0.6508, 0.1856, 0.5247]])"]},"metadata":{},"execution_count":57},{"output_type":"stream","name":"stdout","text":["time: 3.31 ms (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"code","source":["ones_tensor = torch.ones(shape)\n","ones_tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wVPD_mY7Rtfo","executionInfo":{"status":"ok","timestamp":1722975349336,"user_tz":-180,"elapsed":19,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"a19078c0-2ad2-4f08-d343-bd8467d1c8cf"},"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1., 1.],\n","        [1., 1., 1.]])"]},"metadata":{},"execution_count":58},{"output_type":"stream","name":"stdout","text":["time: 3.45 ms (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"code","source":["zeros_tensor = torch.zeros(shape)\n","zeros_tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FMyZH-PDRvpA","executionInfo":{"status":"ok","timestamp":1722975349337,"user_tz":-180,"elapsed":18,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"c7013d72-bb83-43b2-d71c-561ef38f264d"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])"]},"metadata":{},"execution_count":59},{"output_type":"stream","name":"stdout","text":["time: 3.69 ms (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"markdown","source":["# Tensor Attributes"],"metadata":{"id":"RWiCLFxhR3BZ"}},{"cell_type":"code","source":["tensor = torch.rand(3,4)\n","print(f\"Shape of tensor: {tensor.shape}\")\n","print(f\"Datatype of tensor: {tensor.dtype}\")\n","print(f\"Device tensor is stored on: {tensor.device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6psvOpVSR5JK","executionInfo":{"status":"ok","timestamp":1722975349337,"user_tz":-180,"elapsed":17,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"fdd411fa-8db1-4470-ba12-c79e4ff9043b"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of tensor: torch.Size([3, 4])\n","Datatype of tensor: torch.float32\n","Device tensor is stored on: cpu\n","time: 775 µs (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"markdown","source":["# Tensor Operations"],"metadata":{"id":"O0D7ch54SDqf"}},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    tensor = tensor.to('cuda')\n","    print(f\"Device tensor is stored on: {tensor.device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"666IPJTbSJ82","executionInfo":{"status":"ok","timestamp":1722975350506,"user_tz":-180,"elapsed":1185,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"601c6543-59dd-41eb-ee37-a70f0f2b1c40"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Device tensor is stored on: cuda:0\n","time: 776 µs (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"markdown","source":["## Indexing/Slicing"],"metadata":{"id":"7SrwwMh1SdSB"}},{"cell_type":"code","source":["tensor = torch.ones(4, 4)\n","tensor[:,1] = 0\n","tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bvpbmuwJSff1","executionInfo":{"status":"ok","timestamp":1722975350506,"user_tz":-180,"elapsed":41,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"63271794-55ed-4069-f9a8-d5cdfff5764a"},"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])"]},"metadata":{},"execution_count":62},{"output_type":"stream","name":"stdout","text":["time: 4.96 ms (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"markdown","source":["## Joining Tensors"],"metadata":{"id":"o8VOu4pSSqEE"}},{"cell_type":"code","source":["t1 = torch.cat([tensor, tensor, tensor], dim=1)\n","t1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IA0YHXNqSuE2","executionInfo":{"status":"ok","timestamp":1722975350506,"user_tz":-180,"elapsed":38,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"b8e45a2b-93ab-4304-91ae-5d72a0457d43"},"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])"]},"metadata":{},"execution_count":63},{"output_type":"stream","name":"stdout","text":["time: 5.85 ms (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"markdown","source":["## Multiplying Tensors"],"metadata":{"id":"fbVev28qS4KP"}},{"cell_type":"markdown","source":["- element-wise product"],"metadata":{"id":"BhpEmb9ITgZe"}},{"cell_type":"code","source":["# This computes the element-wise product\n","print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n","\n","# Alternative syntax:\n","print(f\"tensor * tensor \\n {tensor * tensor}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cot0gTjqS6Et","executionInfo":{"status":"ok","timestamp":1722975350506,"user_tz":-180,"elapsed":35,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"642bb4da-29e5-48c2-b525-e44ee5f08ca9"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor.mul(tensor) \n"," tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]]) \n","\n","tensor * tensor \n"," tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n","time: 2.97 ms (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"markdown","source":["- matrix multiplication"],"metadata":{"id":"g6bHr4JaTixY"}},{"cell_type":"code","source":["print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n","# Alternative syntax:\n","print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UWGD4V6MTakF","executionInfo":{"status":"ok","timestamp":1722975350506,"user_tz":-180,"elapsed":33,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"a8fa59ac-751c-4227-ba80-d23e481db2b0"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor.matmul(tensor.T) \n"," tensor([[3., 3., 3., 3.],\n","        [3., 3., 3., 3.],\n","        [3., 3., 3., 3.],\n","        [3., 3., 3., 3.]]) \n","\n","tensor @ tensor.T \n"," tensor([[3., 3., 3., 3.],\n","        [3., 3., 3., 3.],\n","        [3., 3., 3., 3.],\n","        [3., 3., 3., 3.]])\n","time: 2.66 ms (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"markdown","source":["## In-place Operations"],"metadata":{"id":"U0lrIv_8TlS5"}},{"cell_type":"code","source":["print(tensor, \"\\n\")\n","tensor.add_(5)\n","print(tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O1EVyZ3JTnQ2","executionInfo":{"status":"ok","timestamp":1722975350506,"user_tz":-180,"elapsed":31,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"db936b4d-81d9-4945-e544-0402ced3cd49"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]]) \n","\n","tensor([[6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.]])\n","time: 4.82 ms (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"markdown","source":["# Bridge with NumPy"],"metadata":{"id":"bODd5zI0TrKO"}},{"cell_type":"markdown","source":["- Tensor to NumPy array: A change in the tensor reflects in the NumPy array"],"metadata":{"id":"08uxFbnVT4MF"}},{"cell_type":"code","source":["t = torch.ones(5)\n","print(f\"t: {t}\")\n","n = t.numpy()\n","print(f\"n: {n}\")\n","\n","t.add_(1)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TCcl76d6T5IB","executionInfo":{"status":"ok","timestamp":1722975350506,"user_tz":-180,"elapsed":29,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"36ccaeca-b873-49fd-dbcb-d7e6e806cf74"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([1., 1., 1., 1., 1.])\n","n: [1. 1. 1. 1. 1.]\n","t: tensor([2., 2., 2., 2., 2.])\n","n: [2. 2. 2. 2. 2.]\n","time: 3.48 ms (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"markdown","source":["- NumPy array to Tensor: Changes in the NumPy array reflects in the tensor."],"metadata":{"id":"5VF18yZxT9Xf"}},{"cell_type":"code","source":["n = np.ones(5)\n","t = torch.from_numpy(n)\n","np.add(n, 1, out=n)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nWIBFgk-T_eq","executionInfo":{"status":"ok","timestamp":1722975350507,"user_tz":-180,"elapsed":29,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"c01d5def-329c-4e9e-951a-9e7168d2c9a8"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n","n: [2. 2. 2. 2. 2.]\n","time: 1.59 ms (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"markdown","source":["# torch.autograd"],"metadata":{"id":"gIxiHREqUZE2"}},{"cell_type":"markdown","source":["## Differentiation in Autograd"],"metadata":{"id":"GQESR2IiUbtT"}},{"cell_type":"code","source":["a = torch.tensor([2., 3.], requires_grad=True)\n","b = torch.tensor([6., 4.], requires_grad=True)"],"metadata":{"id":"3KTstVVAUdqT","executionInfo":{"status":"ok","timestamp":1722975350507,"user_tz":-180,"elapsed":27,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"23fd8992-2a88-4790-80fc-e783698bcb14"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 504 µs (started: 2024-08-06 20:15:48 +00:00)\n"]}]},{"cell_type":"code","source":["Q = 3*a**3 - b**2\n","Q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V4_ZhkTmUiTE","executionInfo":{"status":"ok","timestamp":1722975350507,"user_tz":-180,"elapsed":25,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"e574e70f-85a7-4ffe-c346-f31b8d2294af"},"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-12.,  65.], grad_fn=<SubBackward0>)"]},"metadata":{},"execution_count":70},{"output_type":"stream","name":"stdout","text":["time: 5.17 ms (started: 2024-08-06 20:15:49 +00:00)\n"]}]},{"cell_type":"code","source":["external_grad = torch.tensor([1., 1.])\n","Q.backward(gradient=external_grad)"],"metadata":{"id":"FdFqVfF0UzQC","executionInfo":{"status":"ok","timestamp":1722975350507,"user_tz":-180,"elapsed":23,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4d688a2e-8fe5-4d02-bb9a-2a7fc61cf063"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 769 µs (started: 2024-08-06 20:15:49 +00:00)\n"]}]},{"cell_type":"code","source":["a.grad"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qHfQ5BeeU4qC","executionInfo":{"status":"ok","timestamp":1722975350507,"user_tz":-180,"elapsed":20,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"af7b2efb-9b62-49d3-e73a-d6ce50ee785c"},"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([36., 81.])"]},"metadata":{},"execution_count":72},{"output_type":"stream","name":"stdout","text":["time: 3.64 ms (started: 2024-08-06 20:15:49 +00:00)\n"]}]},{"cell_type":"code","source":["b.grad"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zpa1bGSGU58_","executionInfo":{"status":"ok","timestamp":1722975350507,"user_tz":-180,"elapsed":18,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"a904262e-c7f4-4708-c863-1de4fb77b0e7"},"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-12.,  -8.])"]},"metadata":{},"execution_count":73},{"output_type":"stream","name":"stdout","text":["time: 3.02 ms (started: 2024-08-06 20:15:49 +00:00)\n"]}]},{"cell_type":"code","source":["print(9*a**2 == a.grad)\n","print(-2*b == b.grad)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5NfC46cyVGxx","executionInfo":{"status":"ok","timestamp":1722975350507,"user_tz":-180,"elapsed":16,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"b6c88c37-c666-471b-8f7c-30ec69f3e062"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([True, True])\n","tensor([True, True])\n","time: 3.61 ms (started: 2024-08-06 20:15:49 +00:00)\n"]}]},{"cell_type":"markdown","source":["# Define the network"],"metadata":{"id":"iI89zBKv62ee"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Net(nn.Module):\n","\n","  def __init__(self):\n","    super(Net, self).__init__()\n","    # an affine operation: y = Wx + b\n","    # 784 is the input dimension, and 68 is the output dimenstion of the first hidden layer\n","    self.fc1 = nn.Linear(784, 64)\n","    self.fc2 = nn.Linear(64, 64)\n","    self.fc3 = nn.Linear(64, 10)\n","\n","  def forward(self, x):\n","    # apply the first layer with relu activation\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    x = self.fc3(x)\n","    return x\n","\n","net = Net()\n","print(net)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TFMT_Uhb65dv","outputId":"0bfbcf27-af20-480a-e610-0a3b8c701827","executionInfo":{"status":"ok","timestamp":1722975350507,"user_tz":-180,"elapsed":15,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}}},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["Net(\n","  (fc1): Linear(in_features=784, out_features=64, bias=True)\n","  (fc2): Linear(in_features=64, out_features=64, bias=True)\n","  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",")\n","time: 2.48 ms (started: 2024-08-06 20:15:49 +00:00)\n"]}]},{"cell_type":"code","source":["params = list(net.parameters())\n","print(len(params))\n","\n","for p in params:\n","  print(p.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-3_5IYo7ZHX","outputId":"6c2474a3-4a83-4c39-a225-ed366a3b6853","executionInfo":{"status":"ok","timestamp":1722975350507,"user_tz":-180,"elapsed":13,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}}},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["6\n","torch.Size([64, 784])\n","torch.Size([64])\n","torch.Size([64, 64])\n","torch.Size([64])\n","torch.Size([10, 64])\n","torch.Size([10])\n","time: 744 µs (started: 2024-08-06 20:15:49 +00:00)\n"]}]},{"cell_type":"markdown","source":["# Define a Loss function and optimizer"],"metadata":{"id":"_EMckvxp78gH"}},{"cell_type":"code","source":["import torch.optim as optim\n","\n","loss = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001)"],"metadata":{"id":"hw6ndHlm79EV","executionInfo":{"status":"ok","timestamp":1722975350507,"user_tz":-180,"elapsed":11,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ed4a15a-ceed-42f2-8460-2ba20d01721d"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 2.54 ms (started: 2024-08-06 20:15:49 +00:00)\n"]}]},{"cell_type":"markdown","source":["# Loading a Dataset"],"metadata":{"id":"vD6lgATDKzef"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import matplotlib.pyplot as plt\n","\n","training_data = datasets.MNIST(\n","  root=\"data\",\n","  train=True,\n","  download=True,\n","  transform=ToTensor()\n",")\n","\n","test_data = datasets.MNIST(\n","  root=\"data\",\n","  train=False,\n","  download=True,\n","  transform=ToTensor()\n",")"],"metadata":{"id":"SBSMtqoC9I9j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722975350508,"user_tz":-180,"elapsed":10,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"b0f07417-843b-4ab1-8947-ce4340ef1f06"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 90.2 ms (started: 2024-08-06 20:15:49 +00:00)\n"]}]},{"cell_type":"code","source":["training_data[0][0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XegGOIJHduIL","executionInfo":{"status":"ok","timestamp":1722975350508,"user_tz":-180,"elapsed":8,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"940c5397-b4d7-4367-87fa-1519d7554082"},"execution_count":79,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 28, 28])"]},"metadata":{},"execution_count":79},{"output_type":"stream","name":"stdout","text":["time: 3.24 ms (started: 2024-08-06 20:15:49 +00:00)\n"]}]},{"cell_type":"markdown","source":["# Iterating and Visualizing the Dataset"],"metadata":{"id":"_dUdMc-ebznS"}},{"cell_type":"code","source":["figure = plt.figure(figsize=(8, 8))\n","cols, rows = 3, 3\n","\n","for i in range(1, cols * rows + 1):\n","  sample_idx = torch.randint(len(training_data), size=(1,)).item()\n","  img, label = training_data[sample_idx]\n","  figure.add_subplot(rows, cols, i)\n","  plt.title(\"digit:\" + str(label))\n","  plt.axis(\"off\")\n","  plt.imshow(img.squeeze(), cmap=\"gray\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":693},"outputId":"8bdfb8c9-c216-4fe5-ce88-5472540843a8","id":"rkpScLuBbznZ","executionInfo":{"status":"ok","timestamp":1722975351192,"user_tz":-180,"elapsed":691,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}}},"execution_count":80,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x800 with 9 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["time: 805 ms (started: 2024-08-06 20:15:49 +00:00)\n"]}]},{"cell_type":"markdown","source":["# Preparing your data for training with DataLoaders"],"metadata":{"id":"sc0XMO-GK3ZY"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","train_dataloader = DataLoader(training_data, batch_size=4, shuffle=True)\n","test_dataloader = DataLoader(test_data, batch_size=4, shuffle=True)"],"metadata":{"id":"SsR1m9Pl9YK1","executionInfo":{"status":"ok","timestamp":1722975351192,"user_tz":-180,"elapsed":11,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"16887972-181a-4f87-802a-102e105f0615"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 896 µs (started: 2024-08-06 20:15:50 +00:00)\n"]}]},{"cell_type":"markdown","source":["# Iterate through the DataLoader"],"metadata":{"id":"RHJsmIi2K7J2"}},{"cell_type":"code","source":["# Display image and label.\n","train_features, train_labels = next(iter(train_dataloader))\n","print(f\"Feature batch shape: {train_features.size()}\")\n","print(f\"Labels batch shape: {train_labels.size()}\")\n","img = train_features[0].squeeze()\n","label = train_labels[0]\n","plt.imshow(img, cmap=\"gray\")\n","plt.show()\n","print(f\"Label: {label}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":503},"id":"w8Y3LLC79ZsC","outputId":"fd6f3c44-8c5b-41c7-a31c-8955699fe133","executionInfo":{"status":"ok","timestamp":1722975351192,"user_tz":-180,"elapsed":8,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}}},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["Feature batch shape: torch.Size([4, 1, 28, 28])\n","Labels batch shape: torch.Size([4])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Label: 4\n","time: 239 ms (started: 2024-08-06 20:15:50 +00:00)\n"]}]},{"cell_type":"markdown","source":["# Train the network"],"metadata":{"id":"zO9BxIBkK9Ni"}},{"cell_type":"code","source":["for epoch in range(2): # loop over the dataset multiple times\n","\n","  running_loss = 0.0\n","  for i, data in enumerate(train_dataloader, 0):\n","    # get the inputs; data is a list of [inputs, labels]\n","    inputs, labels = data\n","    # zero the parameter gradients\n","    optimizer.zero_grad()\n","\n","    # forward + backward + optimize\n","    outputs = net(torch.flatten(inputs,1))\n","    iteration_loss = loss(outputs, labels)\n","    iteration_loss.backward()\n","    optimizer.step()\n","\n","    # print statistics\n","    running_loss += iteration_loss.item()\n","    if i % 2000 == 1999: # print every 2000 mini-batches\n","      print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n","      running_loss = 0.0\n","\n","print('Finished Training')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Ft-mnab9kGS","outputId":"e1aab6a3-c224-415b-a92b-8ac4366b558c","executionInfo":{"status":"ok","timestamp":1722975412319,"user_tz":-180,"elapsed":61132,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}}},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["[1,  2000] loss: 2.263\n","[1,  4000] loss: 2.112\n","[1,  6000] loss: 1.763\n","[1,  8000] loss: 1.279\n","[1, 10000] loss: 0.875\n","[1, 12000] loss: 0.673\n","[1, 14000] loss: 0.583\n","[2,  2000] loss: 0.494\n","[2,  4000] loss: 0.468\n","[2,  6000] loss: 0.452\n","[2,  8000] loss: 0.419\n","[2, 10000] loss: 0.401\n","[2, 12000] loss: 0.368\n","[2, 14000] loss: 0.374\n","Finished Training\n","time: 1min 1s (started: 2024-08-06 20:15:50 +00:00)\n"]}]},{"cell_type":"markdown","source":["# Test the network on the test data"],"metadata":{"id":"3bNr6fNpLBgj"}},{"cell_type":"code","source":["PATH = './my_net.pth'\n","torch.save(net.state_dict(), PATH)"],"metadata":{"id":"edqjMAUyJ_1M","executionInfo":{"status":"ok","timestamp":1722975412319,"user_tz":-180,"elapsed":9,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3a6063a2-8f00-482f-9236-9e7104b90cce"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 2.8 ms (started: 2024-08-06 20:16:51 +00:00)\n"]}]},{"cell_type":"code","source":["net = Net()\n","net.load_state_dict(torch.load(PATH))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mUYTvktsKAt9","outputId":"80427636-9ccf-4cfa-dca3-a0125d13c5f1","executionInfo":{"status":"ok","timestamp":1722975412319,"user_tz":-180,"elapsed":6,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}}},"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":85},{"output_type":"stream","name":"stdout","text":["time: 6.13 ms (started: 2024-08-06 20:16:51 +00:00)\n"]}]},{"cell_type":"code","source":["correct = 0\n","total = 0\n","# since we're not training, we don't need to calculate the gradients for our outputs\n","with torch.no_grad():\n","  for data in test_dataloader:\n","    images, labels = data\n","    # calculate outputs by running images through the network\n","    outputs = net(torch.flatten(images,1))\n","    # the class with the highest energy is what we choose as prediction\n","    _, predicted = torch.max(outputs.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum().item()\n","print(f'Accuracy of the network on the 10000 test images: {100 * correct// total} %')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TAO8dtv4KDbZ","outputId":"fb4da4b4-5eed-4310-f11e-ee4222125aca","executionInfo":{"status":"ok","timestamp":1722975415299,"user_tz":-180,"elapsed":2982,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}}},"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 90 %\n","time: 2.25 s (started: 2024-08-06 20:16:51 +00:00)\n"]}]},{"cell_type":"markdown","source":["# Training on GPU"],"metadata":{"id":"Pjxa4_pvLFgW"}},{"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","# Assuming that we are on a CUDA machine, this should print a CUDA device:\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XXl9R15CKWlp","outputId":"7e5592f5-513c-4942-c8de-ea1d138454fe","executionInfo":{"status":"ok","timestamp":1722975415300,"user_tz":-180,"elapsed":6,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}}},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n","time: 1.52 ms (started: 2024-08-06 20:16:53 +00:00)\n"]}]},{"cell_type":"code","source":["net = Net()\n","\n","net.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KTRdWzO7KZFK","outputId":"e9694a4d-e716-44a5-f03f-5a2ced896915","executionInfo":{"status":"ok","timestamp":1722975415300,"user_tz":-180,"elapsed":6,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}}},"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (fc1): Linear(in_features=784, out_features=64, bias=True)\n","  (fc2): Linear(in_features=64, out_features=64, bias=True)\n","  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":88},{"output_type":"stream","name":"stdout","text":["time: 5.47 ms (started: 2024-08-06 20:16:53 +00:00)\n"]}]},{"cell_type":"markdown","source":["<a name=\"Tasks\"></a>\n","# **Tasks**"],"metadata":{"id":"Nvcs3z_ARU7a"}},{"cell_type":"markdown","source":["## Task 1"],"metadata":{"id":"-9tPvL2QVdDu"}},{"cell_type":"code","source":["x1 = torch.tensor([1.], requires_grad=True)\n","x2 = torch.tensor([1.], requires_grad=True)\n","\n","y = (3*x1 - 2*x2 - 2) ** 2\n","y.backward()\n","\n","print(x1.grad)\n","print(x2.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MDLPaJdZVdxg","executionInfo":{"status":"ok","timestamp":1722975956953,"user_tz":-180,"elapsed":26,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"b2327c70-1061-427c-a2d4-056b5d7ec68c"},"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-6.])\n","tensor([4.])\n","time: 3.46 ms (started: 2024-08-06 20:25:56 +00:00)\n"]}]},{"cell_type":"code","source":["print((18*x1 - 12*x2 - 12) == x1.grad)\n","print((8*x2 - 12*x2 + 8) == x2.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7oKof0fxXxpJ","executionInfo":{"status":"ok","timestamp":1722975956953,"user_tz":-180,"elapsed":11,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"27cd0975-7cf0-413f-c05a-eea155e088d0"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([True])\n","tensor([True])\n","time: 1.36 ms (started: 2024-08-06 20:25:56 +00:00)\n"]}]},{"cell_type":"markdown","source":["## Task 2"],"metadata":{"id":"BaigovjO7dH8"}},{"cell_type":"markdown","source":["- **torch.Size([64, 784]):** This represents the weight matrix for the first layer of the neural network. It has a size of 64 (output features) by 784 (input features).\n","\n","- **torch.Size([64]):** This represents the bias vector for the first layer. It has a size of 64, corresponding to the number of output features in the first layer.\n","\n","- **torch.Size([64, 64]):** This represents the weight matrix for the second layer of the neural network. It has a size of 64 (output features) by 64 (input features).\n","\n","- **torch.Size([64]):** This represents the bias vector for the second layer. It has a size of 64, corresponding to the number of output features in the second layer.\n","\n","- **torch.Size([10, 64]):** This represents the weight matrix for the third (output) layer of the neural network. It has a size of 10 (output classes) by 64 (input features from the previous layer).\n","\n","- **torch.Size([10]):** This represents the bias vector for the third layer. It has a size of 10, corresponding to the number of output classes in the network."],"metadata":{"id":"Z3-di0fk80Oe"}},{"cell_type":"code","source":["input = torch.randn(1, 784)\n","out = net(input)\n","\n","print(out)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mM8hrnFM7pPM","outputId":"9c57018c-a770-4b12-eb85-23d6b902e6f3","executionInfo":{"status":"ok","timestamp":1722975956953,"user_tz":-180,"elapsed":9,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}}},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-173.3796, -164.6014, -201.3859, -131.5352, -219.1172,  -18.7918,\n","         -160.7294, -153.5840, -167.1392, -142.1912]],\n","       grad_fn=<AddmmBackward0>)\n","time: 2.96 ms (started: 2024-08-06 20:25:56 +00:00)\n"]}]},{"cell_type":"markdown","source":["## Task 3"],"metadata":{"id":"fJcyDW897pEC"}},{"cell_type":"code","source":["input = torch.randn(4, 784)\n","out = net(input)\n","\n","print(out)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V9kQ4Rsa7083","outputId":"06356498-ffb5-4e20-af72-c05b7251e8b5","executionInfo":{"status":"ok","timestamp":1722975956953,"user_tz":-180,"elapsed":7,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}}},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-141.9355, -187.7236, -186.9838, -122.3462, -166.6523,  -35.1292,\n","         -159.3612, -146.6368, -121.6866,  -82.7576],\n","        [  -9.8638,  -32.0218,  -19.4798,  -35.0303,  -14.6128,  -27.3734,\n","          -20.3717,   -9.5742,  -29.7955,  -22.9758],\n","        [ -88.1020, -210.0890, -117.4113, -132.0750, -114.8233,  -94.4386,\n","         -152.4959,  -59.8701, -200.8784,  -90.7383],\n","        [ -98.5790, -102.1735, -123.5575,  -41.9450, -131.8499,   17.1098,\n","         -101.6135,  -89.4320, -103.9885,  -46.9661]],\n","       grad_fn=<AddmmBackward0>)\n","time: 4.43 ms (started: 2024-08-06 20:25:56 +00:00)\n"]}]},{"cell_type":"markdown","source":["## Task 4"],"metadata":{"id":"udM_XNUNJ561"}},{"cell_type":"markdown","source":["- **Epoch**: An epoch is a single pass through the entire training dataset. The outer loop for epoch in range(2) indicates that the training process will loop over the dataset two times.\n","\n","- **Forward Pass**: The forward pass is the process of passing input data through the neural network to compute the predicted outputs. In this code, outputs = net(torch.flatten(inputs, 1)) represents the forward pass, where inputs are passed through the neural network (net) after being flattened along the second dimension using torch.flatten(inputs, 1).\n","\n","- **Backward Pass**: The backward pass, also known as backpropagation, is the process of computing gradients of the loss function with respect to the network's parameters. This is done using the backward() method: iteration_loss.backward(). It computes gradients for all the tensors used to compute iteration_loss.\n","\n","\n","- **torch.flatten(inputs, 1)**: This function reshapes the input tensor inputs to have a flattened shape along the second dimension (dimension 1). It's likely used to prepare the input data for the neural network if it expects a flattened representation.\n","\n","- **Optimizer**: optimizer.step() updates the parameters of the neural network using the computed gradients and the optimization algorithm (e.g., SGD, Adam) to minimize the loss. It adjusts the network's weights and biases based on the computed gradients and the specified optimization strategy."],"metadata":{"id":"PSJygMBNJ59p"}},{"cell_type":"markdown","source":["## Task 5:"],"metadata":{"id":"rNHGyEwjKSPK"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","# Assuming net is the previously defined neural network with 2 hidden layers\n","\n","class ThreeHiddenLayerNet(nn.Module):\n","    def __init__(self):\n","        super(ThreeHiddenLayerNet, self).__init__()\n","        self.fc1 = nn.Linear(784, 64)  # First hidden layer\n","        self.fc2 = nn.Linear(64, 64)   # Second hidden layer\n","        self.fc3 = nn.Linear(64, 64)   # Third hidden layer\n","        self.fc4 = nn.Linear(64, 10)   # Output layer\n","\n","    def forward(self, x):\n","        x = torch.flatten(x, 1)\n","        x = torch.relu(self.fc1(x))   # ReLU activation for first hidden layer\n","        x = torch.relu(self.fc2(x))   # ReLU activation for second hidden layer\n","        x = torch.relu(self.fc3(x))   # ReLU activation for third hidden layer\n","        x = self.fc4(x)               # Output layer without activation (for example, using CrossEntropyLoss)\n","        return x"],"metadata":{"id":"-g107n19Q2Je","executionInfo":{"status":"ok","timestamp":1722975956954,"user_tz":-180,"elapsed":6,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7d0395f9-fe94-4c13-f84c-e39dc699c656"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 619 µs (started: 2024-08-06 20:25:56 +00:00)\n"]}]},{"cell_type":"code","source":["# Initialize the network\n","net = ThreeHiddenLayerNet()\n","\n","# Define the loss function and optimizer\n","loss = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001)\n","\n","for epoch in range(2): # loop over the dataset multiple times\n","\n","  running_loss = 0.0\n","  for i, data in enumerate(train_dataloader, 0):\n","    inputs, labels = data\n","    optimizer.zero_grad()\n","\n","    outputs = net(torch.flatten(inputs,1))\n","    iteration_loss = loss(outputs, labels)\n","    iteration_loss.backward()\n","    optimizer.step()\n","\n","    running_loss += iteration_loss.item()\n","    if i % 2000 == 1999: # print every 2000 mini-batches\n","      print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n","      running_loss = 0.0\n","\n","print('Finished Training')\n","\n","correct = 0\n","total = 0\n","# since we're not training, we don't need to calculate the gradients for our outputs\n","with torch.no_grad():\n","  for data in test_dataloader:\n","    images, labels = data\n","    # calculate outputs by running images through the network\n","    outputs = net(torch.flatten(images,1))\n","    # the class with the highest energy is what we choose as prediction\n","    _, predicted = torch.max(outputs.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum().item()\n","\n","print(f'Accuracy of the network on the 10000 test images: {100 * correct// total} %')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CuuNNRQzqrcK","outputId":"19058980-d552-47b7-fa63-8b9522106f1c","executionInfo":{"status":"ok","timestamp":1722976014160,"user_tz":-180,"elapsed":57210,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}}},"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["[1,  2000] loss: 2.305\n","[1,  4000] loss: 2.294\n","[1,  6000] loss: 2.277\n","[1,  8000] loss: 2.244\n","[1, 10000] loss: 2.153\n","[1, 12000] loss: 1.888\n","[1, 14000] loss: 1.453\n","[2,  2000] loss: 0.930\n","[2,  4000] loss: 0.772\n","[2,  6000] loss: 0.671\n","[2,  8000] loss: 0.615\n","[2, 10000] loss: 0.544\n","[2, 12000] loss: 0.520\n","[2, 14000] loss: 0.494\n","Finished Training\n","Accuracy of the network on the 10000 test images: 86 %\n","time: 57.1 s (started: 2024-08-06 20:25:56 +00:00)\n"]}]},{"cell_type":"markdown","source":["## Task 6"],"metadata":{"id":"EgSQEc66KTI3"}},{"cell_type":"code","source":["# Initialize the network\n","net = ThreeHiddenLayerNet()\n","\n","# Use Adam optimizer with a learning rate of 0.001\n","loss = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","for epoch in range(2):  # loop over the dataset multiple times\n","    running_loss = 0.0\n","    for i, data in enumerate(train_dataloader, 0):\n","        inputs, labels = data\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        iteration_loss = loss(outputs, labels)\n","        iteration_loss.backward()\n","        optimizer.step()\n","        running_loss += iteration_loss.item()\n","        if i % 2000 == 1999:  # print every 2000 mini-batches\n","            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n","            running_loss = 0.0\n","\n","print('Finished Training')\n","\n","correct = 0\n","total = 0\n","# since we're not training, we don't need to calculate the gradients for our outputs\n","with torch.no_grad():\n","  for data in test_dataloader:\n","    images, labels = data\n","    # calculate outputs by running images through the network\n","    outputs = net(torch.flatten(images,1))\n","    # the class with the highest energy is what we choose as prediction\n","    _, predicted = torch.max(outputs.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum().item()\n","\n","print(f'Accuracy of the network on the 10000 test images: {100 * correct// total} %')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VTBAqk5uKUpI","outputId":"9c121f95-905f-482a-860a-c61b5e015abe","executionInfo":{"status":"ok","timestamp":1722976114435,"user_tz":-180,"elapsed":100307,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}}},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["[1,  2000] loss: 0.593\n","[1,  4000] loss: 0.308\n","[1,  6000] loss: 0.236\n","[1,  8000] loss: 0.205\n","[1, 10000] loss: 0.200\n","[1, 12000] loss: 0.179\n","[1, 14000] loss: 0.165\n","[2,  2000] loss: 0.131\n","[2,  4000] loss: 0.141\n","[2,  6000] loss: 0.125\n","[2,  8000] loss: 0.138\n","[2, 10000] loss: 0.126\n","[2, 12000] loss: 0.116\n","[2, 14000] loss: 0.122\n","Finished Training\n","Accuracy of the network on the 10000 test images: 96 %\n","time: 1min 40s (started: 2024-08-06 20:26:53 +00:00)\n"]}]},{"cell_type":"markdown","source":["## Task 7"],"metadata":{"id":"s6v1S2VYKdXV"}},{"cell_type":"markdown","source":["Working with a small network:"],"metadata":{"id":"TLqnx02fwbDJ"}},{"cell_type":"code","source":["loss = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001)\n","\n","for epoch in range(2): # loop over the dataset multiple times\n","\n","  running_loss = 0.0\n","  for i, data in enumerate(train_dataloader, 0):\n","    # get the inputs; data is a list of [inputs, labels]\n","    inputs, labels = data[0].to(device), data[1].to(device)\n","    # zero the parameter gradients\n","    optimizer.zero_grad()\n","\n","    # forward + backward + optimize\n","    outputs = net(torch.flatten(inputs,1))\n","    iteration_loss = loss(outputs, labels)\n","    iteration_loss.backward()\n","    optimizer.step()\n","\n","    # print statistics\n","    running_loss += iteration_loss.item()\n","    if i % 2000 == 1999: # print every 2000 mini-batches\n","      print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n","      running_loss = 0.0\n","\n","print('Finished Training')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lmqLlejeKbEh","outputId":"1d3fdf29-3793-4768-b868-bbb964d1fa6e","executionInfo":{"status":"ok","timestamp":1722975479852,"user_tz":-180,"elapsed":64555,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1,  2000] loss: 2.265\n","[1,  4000] loss: 2.141\n","[1,  6000] loss: 1.850\n","[1,  8000] loss: 1.321\n","[1, 10000] loss: 0.896\n","[1, 12000] loss: 0.680\n","[1, 14000] loss: 0.601\n","[2,  2000] loss: 0.506\n","[2,  4000] loss: 0.467\n","[2,  6000] loss: 0.442\n","[2,  8000] loss: 0.419\n","[2, 10000] loss: 0.386\n","[2, 12000] loss: 0.390\n","[2, 14000] loss: 0.374\n","Finished Training\n","time: 1min 5s (started: 2024-08-06 20:16:53 +00:00)\n"]}]},{"cell_type":"markdown","source":["CPU time: 1min 1s\n","\n","GPU time: 1min 5s\n","\n","Working with two hidden layers, the speedup isn't that significant."],"metadata":{"id":"ytXAdevch2ow"}},{"cell_type":"markdown","source":["- Let's try to increase the size of the network, keeping the same number of hidden layers:"],"metadata":{"id":"w6SOddtTZOno"}},{"cell_type":"code","source":["class LargerTwoHiddenLayerNet(nn.Module):\n","    def __init__(self):\n","        super(LargerTwoHiddenLayerNet, self).__init__()\n","        self.fc1 = nn.Linear(784, 512)  # First hidden layer with 128 neurons\n","        self.fc2 = nn.Linear(512, 512)  # Second hidden layer with 128 neurons\n","        self.fc3 = nn.Linear(512, 10)   # Output layer with 10 neurons\n","\n","    def forward(self, x):\n","        x = torch.flatten(x, 1)\n","        x = torch.relu(self.fc1(x))   # ReLU activation for first hidden layer\n","        x = torch.relu(self.fc2(x))   # ReLU activation for second hidden layer\n","        x = self.fc3(x)               # Output layer without activation (for example, using CrossEntropyLoss)\n","        return x"],"metadata":{"id":"nXfcNnASwvAU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722975479852,"user_tz":-180,"elapsed":51,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"outputId":"b3ae182b-2e2c-413c-e1d7-53b4bbd4c4f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 747 µs (started: 2024-08-06 20:17:59 +00:00)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Training on {device}\")\n","\n","# Initialize the larger network and move it to the device (GPU if available)\n","net = LargerTwoHiddenLayerNet().to(device)\n","\n","# Define the loss function\n","loss = nn.CrossEntropyLoss()\n","\n","# Use Adam optimizer with a learning rate of 0.001\n","optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","# Assuming train_dataloader contains your training dataset\n","for epoch in range(2):  # loop over the dataset multiple times\n","    running_loss = 0.0\n","    for i, data in enumerate(train_dataloader, 0):\n","        inputs, labels = data\n","        # Move the inputs and labels to the device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        iteration_loss = loss(outputs, labels)\n","        iteration_loss.backward()\n","        optimizer.step()\n","        running_loss += iteration_loss.item()\n","        if i % 2000 == 1999:  # print every 2000 mini-batches\n","            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n","            running_loss = 0.0\n","\n","print('Finished Training')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O6vOusnXmE0s","outputId":"fabdeecd-7aae-4ba5-b90e-9dfa40fadf1a","executionInfo":{"status":"ok","timestamp":1722975555097,"user_tz":-180,"elapsed":75287,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training on cuda:0\n","[1,  2000] loss: 0.432\n","[1,  4000] loss: 0.245\n","[1,  6000] loss: 0.200\n","[1,  8000] loss: 0.178\n","[1, 10000] loss: 0.152\n","[1, 12000] loss: 0.167\n","[1, 14000] loss: 0.143\n","[2,  2000] loss: 0.106\n","[2,  4000] loss: 0.123\n","[2,  6000] loss: 0.112\n","[2,  8000] loss: 0.121\n","[2, 10000] loss: 0.118\n","[2, 12000] loss: 0.116\n","[2, 14000] loss: 0.106\n","Finished Training\n","time: 1min 15s (started: 2024-08-06 20:17:59 +00:00)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","# Assuming net is the previously defined neural network with 3 hidden layers\n","\n","# Check if GPU is available and set the device\n","device = torch.device(\"cpu\")\n","print(f\"Training on {device}\")\n","\n","# Initialize the larger network and move it to the device (GPU if available)\n","net = LargerTwoHiddenLayerNet().to(device)\n","\n","# Define the loss function\n","loss = nn.CrossEntropyLoss()\n","\n","# Use Adam optimizer with a learning rate of 0.001\n","optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","# Assuming train_dataloader contains your training dataset\n","for epoch in range(2):  # loop over the dataset multiple times\n","    running_loss = 0.0\n","    for i, data in enumerate(train_dataloader, 0):\n","        inputs, labels = data\n","        # Move the inputs and labels to the device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        iteration_loss = loss(outputs, labels)\n","        iteration_loss.backward()\n","        optimizer.step()\n","        running_loss += iteration_loss.item()\n","        if i % 2000 == 1999:  # print every 2000 mini-batches\n","            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n","            running_loss = 0.0\n","\n","print('Finished Training')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qwGlLoW7vhyx","outputId":"72279b08-bd99-4e58-dd5a-b6be044cfb2b","executionInfo":{"status":"ok","timestamp":1722975956953,"user_tz":-180,"elapsed":401890,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training on cpu\n","[1,  2000] loss: 0.423\n","[1,  4000] loss: 0.246\n","[1,  6000] loss: 0.196\n","[1,  8000] loss: 0.174\n","[1, 10000] loss: 0.171\n","[1, 12000] loss: 0.159\n","[1, 14000] loss: 0.143\n","[2,  2000] loss: 0.118\n","[2,  4000] loss: 0.097\n","[2,  6000] loss: 0.122\n","[2,  8000] loss: 0.107\n","[2, 10000] loss: 0.110\n","[2, 12000] loss: 0.115\n","[2, 14000] loss: 0.124\n","Finished Training\n","time: 6min 41s (started: 2024-08-06 20:19:14 +00:00)\n"]}]},{"cell_type":"markdown","source":["GPU time: 1min 15s\n","\n","CPU time: 6min 41s\n","\n","The significant difference is vey obvious, working with a bigger size than before."],"metadata":{"id":"91PK3UwYtYEU"}},{"cell_type":"markdown","source":["- Let's try working on the three hidden layers network:"],"metadata":{"id":"UmKfj0LDZuJi"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Training on {device}\")\n","\n","# Initialize the larger network and move it to the device (GPU if available)\n","net = ThreeHiddenLayerNet().to(device)\n","\n","# Define the loss function\n","loss = nn.CrossEntropyLoss()\n","\n","# Use Adam optimizer with a learning rate of 0.001\n","optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","# Assuming train_dataloader contains your training dataset\n","for epoch in range(2):  # loop over the dataset multiple times\n","    running_loss = 0.0\n","    for i, data in enumerate(train_dataloader, 0):\n","        inputs, labels = data\n","        # Move the inputs and labels to the device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        iteration_loss = loss(outputs, labels)\n","        iteration_loss.backward()\n","        optimizer.step()\n","        running_loss += iteration_loss.item()\n","        if i % 2000 == 1999:  # print every 2000 mini-batches\n","            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n","            running_loss = 0.0\n","\n","print('Finished Training')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9cb96ed5-ddc4-4a7c-9f21-4348ef21d30d","executionInfo":{"status":"ok","timestamp":1722976611143,"user_tz":-180,"elapsed":77179,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"id":"2QoZgP72ZyQV"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["Training on cuda:0\n","[1,  2000] loss: 0.606\n","[1,  4000] loss: 0.299\n","[1,  6000] loss: 0.241\n","[1,  8000] loss: 0.209\n","[1, 10000] loss: 0.186\n","[1, 12000] loss: 0.178\n","[1, 14000] loss: 0.171\n","[2,  2000] loss: 0.128\n","[2,  4000] loss: 0.143\n","[2,  6000] loss: 0.146\n","[2,  8000] loss: 0.125\n","[2, 10000] loss: 0.125\n","[2, 12000] loss: 0.120\n","[2, 14000] loss: 0.121\n","Finished Training\n","time: 1min 16s (started: 2024-08-06 20:35:33 +00:00)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","# Assuming net is the previously defined neural network with 3 hidden layers\n","\n","# Check if GPU is available and set the device\n","device = torch.device(\"cpu\")\n","print(f\"Training on {device}\")\n","\n","# Initialize the larger network and move it to the device (GPU if available)\n","net = ThreeHiddenLayerNet().to(device)\n","\n","# Define the loss function\n","loss = nn.CrossEntropyLoss()\n","\n","# Use Adam optimizer with a learning rate of 0.001\n","optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","# Assuming train_dataloader contains your training dataset\n","for epoch in range(2):  # loop over the dataset multiple times\n","    running_loss = 0.0\n","    for i, data in enumerate(train_dataloader, 0):\n","        inputs, labels = data\n","        # Move the inputs and labels to the device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        iteration_loss = loss(outputs, labels)\n","        iteration_loss.backward()\n","        optimizer.step()\n","        running_loss += iteration_loss.item()\n","        if i % 2000 == 1999:  # print every 2000 mini-batches\n","            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n","            running_loss = 0.0\n","\n","print('Finished Training')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bf9a8b14-d9e1-40b1-9140-98aca7dc2f0e","executionInfo":{"status":"ok","timestamp":1722976710694,"user_tz":-180,"elapsed":99560,"user":{"displayName":"Osama Shoora","userId":"06055927753721480644"}},"id":"FjysFevPZyQd"},"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["Training on cpu\n","[1,  2000] loss: 0.619\n","[1,  4000] loss: 0.298\n","[1,  6000] loss: 0.250\n","[1,  8000] loss: 0.228\n","[1, 10000] loss: 0.193\n","[1, 12000] loss: 0.180\n","[1, 14000] loss: 0.166\n","[2,  2000] loss: 0.141\n","[2,  4000] loss: 0.144\n","[2,  6000] loss: 0.126\n","[2,  8000] loss: 0.129\n","[2, 10000] loss: 0.139\n","[2, 12000] loss: 0.140\n","[2, 14000] loss: 0.131\n","Finished Training\n","time: 1min 38s (started: 2024-08-06 20:36:50 +00:00)\n"]}]},{"cell_type":"markdown","source":["GPU time: 1min 16s\n","\n","CPU time: 1min 38s\n","\n","There's a slight different, working with three hidden layers instead of two. So, maybe the number of neurons in each layer plays a big role in the performance."],"metadata":{"id":"avHV2nCcaWH1"}}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}