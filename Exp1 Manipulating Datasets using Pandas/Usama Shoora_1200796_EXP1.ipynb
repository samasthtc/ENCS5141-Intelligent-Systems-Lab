{"cells":[{"cell_type":"markdown","metadata":{"id":"hTqV3sb0dGJa"},"source":["# [**Jump to Tasks**](#Tasks)"]},{"cell_type":"markdown","source":["<hr>"],"metadata":{"id":"TqlNfjxaeC_V"}},{"cell_type":"markdown","metadata":{"id":"fDW3ahIsdGJc"},"source":["## Examples"]},{"cell_type":"markdown","metadata":{"id":"Py1Y2lsgcCTT"},"source":["### **Example1**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9I8kdnWQbtkf","outputId":"f40a5076-66e9-496e-bef0-db2c5a439962"},"outputs":[{"name":"stdout","output_type":"stream","text":["0    1\n","1    7\n","2    2\n","dtype: int64\n"]}],"source":["import pandas as pd\n","a = [1,7,2]\n","my_series = pd.Series(a)\n","print(my_series)"]},{"cell_type":"markdown","metadata":{"id":"1w6mZNI0cAAE"},"source":["### **Example2**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uOPVp7CTcNZ6","outputId":"46a2cc78-dfb8-4903-aa8d-f32d8e3e0598"},"outputs":[{"name":"stdout","output_type":"stream","text":["day1    420\n","day2    380\n","day3    390\n","dtype: int64\n"]}],"source":["calories = {\"day1\": 420, \"day2\": 380, \"day3\": 390}\n","my_series2 = pd.Series(calories)\n","print(my_series2)"]},{"cell_type":"markdown","metadata":{"id":"UT7vlCXGc5EW"},"source":["### **Example3**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LEbvwS0tc7i2","outputId":"84c96bb0-eea6-46c7-c709-35d331f3a01a"},"outputs":[{"name":"stdout","output_type":"stream","text":["    0\n","0  10\n","1  20\n","2  30\n","3  40\n"]}],"source":["d = pd.Series([10, 20, 30, 40])\n","df = pd.DataFrame(d)\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"vDL5FS8hdI4U"},"source":["### **Example4**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ksjqsKEodKx-","outputId":"8190fcf3-3811-494c-ff44-46d9d4d94818"},"outputs":[{"name":"stdout","output_type":"stream","text":["    Name  Age\n","0  Ahmad   20\n","1    Ali   19\n","2  Osama   22\n","3  Mutaz   24\n"]}],"source":["data = {'Name': ['Ahmad', 'Ali', 'Osama', 'Mutaz'],\n","        'Age': [20, 19, 22, 24]}\n","df = pd.DataFrame(data)\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"02COhrLIV1mI"},"source":["### **Example5**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CrfAWTM3V1mJ","outputId":"5c48791f-0526-4a51-93eb-7d57ec3a070e"},"outputs":[{"name":"stdout","output_type":"stream","text":["   calories  duration\n","0       420        50\n","1       380        40\n","2       390        45\n"]}],"source":["data = {\n","  \"calories\": [420, 380, 390],\n","  \"duration\": [50, 40, 45]\n","}\n","\n","myvar = pd.DataFrame(data)\n","print(myvar)"]},{"cell_type":"markdown","metadata":{"id":"oilPpdQIV1mJ"},"source":["### **Example6**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cz5o5_vkV1mJ","outputId":"4393091c-a2d9-4b5e-c437-bc6778e23716"},"outputs":[{"name":"stdout","output_type":"stream","text":["    Waiter  total_bill   tip smoker  day    time  size\n","0       10       16.99  1.01     No  Sun  Dinner     2\n","1       10       10.34  1.66     No  Sun  Dinner     3\n","2       11       21.01  3.50     No  Sun  Dinner     3\n","3       11       23.68  3.31     No  Sun  Dinner     2\n","4       22       24.59  3.61     No  Sun  Dinner     4\n","5       13       25.29  4.71     No  Sun  Dinner     4\n","6       10        8.77  2.00     No  Sun  Dinner     2\n","7       30       26.88  3.12     No  Sun  Dinner     4\n","8       15       15.04  1.96     No  Sun  Dinner     2\n","9       30       14.78  3.23     No  Sun  Dinner     2\n","10      15       10.27  1.71     No  Sun  Dinner     2\n","11      30       35.26  5.00     No  Sun  Dinner     4\n","12      10       15.42  1.57     No  Sun  Dinner     2\n","13      11       18.43  3.00     No  Sun  Dinner     4\n","14      11       14.83  3.02     No  Sun  Dinner     2\n","15      30       21.58  3.92     No  Sun  Dinner     2\n","16      11       10.33  1.67     No  Sun  Dinner     3\n","17      10       16.29  3.71     No  Sun  Dinner     3\n","18      12       16.97  3.50     No  Sun  Dinner     3\n","19      12       20.65  3.35     No  Sat  Dinner     3\n","20      11       17.92  4.08     No  Sat  Dinner     2\n","21      11       20.29  2.75     No  Sat  Dinner     2\n","22      10       15.77  2.23     No  Sat  Dinner     2\n","23      33       39.42  7.58     No  Sat  Dinner     4\n","24      33       19.82  3.18     No  Sat  Dinner     2\n"]}],"source":["df = pd.read_csv('Dinner.csv')\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"MVOc72h1V1mJ"},"source":["### **Examples7-10**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xdiHK3iJV1mJ","outputId":"c0b20ee7-7e63-4a55-85bc-9ff97d4e549a"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Waiter  total_bill   tip smoker   day   time  size\n","0      10       27.20  4.00     No  Thur  Lunch     4\n","1      10       22.76  3.00     No  Thur  Lunch     2\n","2      11       17.29  2.71     No  Thur  Lunch     2\n","3      11       19.44  3.00    Yes  Thur  Lunch     2\n","4      33       16.66  3.40     No  Thur  Lunch     2\n","\n","   Waiter       type\n","1      11  part time\n","2      33  full time\n","3      30  full time\n","4      12  part time\n","5      20  part time\n","\n","shapes:\n"," (13, 7) (6, 2) \n","\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 13 entries, 0 to 12\n","Data columns (total 7 columns):\n"," #   Column      Non-Null Count  Dtype  \n","---  ------      --------------  -----  \n"," 0   Waiter      13 non-null     int64  \n"," 1   total_bill  13 non-null     float64\n"," 2   tip         13 non-null     float64\n"," 3   smoker      13 non-null     object \n"," 4   day         13 non-null     object \n"," 5   time        13 non-null     object \n"," 6   size        13 non-null     int64  \n","dtypes: float64(2), int64(2), object(3)\n","memory usage: 860.0+ bytes\n","None \n","\n","\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 6 entries, 0 to 5\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   Waiter  6 non-null      int64 \n"," 1   type    6 non-null      object\n","dtypes: int64(1), object(1)\n","memory usage: 228.0+ bytes\n","None\n"]}],"source":["#exp7\n","df = pd.read_csv('Lunch.csv')\n","print(df.head())\n","print()\n","\n","#exp8\n","df2 = pd.read_csv('Waiters.csv')\n","print(df2.tail())\n","\n","#exp9\n","print(\"\\nshapes:\\n\", df.shape, df2.shape, \"\\n\")\n","\n","#exp10\n","print(df.info(), \"\\n\\n\")\n","print(df2.info())"]},{"cell_type":"markdown","metadata":{"id":"ixf6Ri_eV1mJ"},"source":["### **Examples11&12**"]},{"cell_type":"markdown","metadata":{"id":"pyYTTth_V1mJ"},"source":["#### **Part1**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lCfk1c6_V1mJ","outputId":"ddea2d80-83c7-406e-8f68-bf503117e94b"},"outputs":[{"name":"stdout","output_type":"stream","text":["   col_5  col_1  col_8\n","0     41      1     71\n","1     42      2     72\n","2     43      3     73\n","3     44      4     74\n","4     45      5     75\n","5     46      6     76\n","6     47      7     77\n","7     48      8     78\n","8     49      9     79\n","9     50     10     80\n","col_1     1\n","col_2    11\n","col_3    21\n","col_4    31\n","col_5    41\n","col_6    51\n","col_7    61\n","col_8    71\n","col_9    81\n","Name: 0, dtype: int64\n","       col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9\n","row_6      6     16     26     36     46     56     66     76     86\n","row_7      7     17     27     37     47     57     67     77     87\n","row_8      8     18     28     38     48     58     68     78     88\n","row_9      9     19     29     39     49     59     69     79     89\n"]}],"source":["df = pd.DataFrame({'col_1': list(range(1, 11)),\n","                   'col_2': list(range(11, 21)),\n","                   'col_3': list(range(21, 31)),\n","                   'col_4': list(range(31, 41)),\n","                   'col_5': list(range(41, 51)),\n","                   'col_6': list(range(51, 61)),\n","                   'col_7': list(range(61, 71)),\n","                   'col_8': list(range(71, 81)),\n","                   'col_9': list(range(81, 91))})\n","#print(df)\n","#print(df.columns)\n","#print(df.index)\n","\n","#using indexing operator\n","print(df[['col_5', 'col_1', 'col_8']])\n","\n","#using loc indexer\n","print(df.loc[0])\n","df.index = ['row_1', 'row_2', 'row_3', 'row_4', 'row_5', 'row_6', 'row_7',\n","            'row_8', 'row_9', 'row_10']\n","\n","print(df.loc['row_6':'row_9'])"]},{"cell_type":"markdown","metadata":{"id":"yFmBPxQ4V1mJ"},"source":["#### **Part2**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xiaHkdm6V1mK","outputId":"5f995141-f7dd-4668-c87e-3eb6997d8207"},"outputs":[{"name":"stdout","output_type":"stream","text":["        col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9\n","row_1       1     11     21     31     41     51     61     71     81\n","row_2       2     12     22     32     42     52     62     72     82\n","row_3       3     13     23     33     43     53     63     73     83\n","row_4       4     14     24     34     44     54     64     74     84\n","row_5       5     15     25     35     45     55     65     75     85\n","row_6       6     16     26     36     46     56     66     76     86\n","row_7       7     17     27     37     47     57     67     77     87\n","row_8       8     18     28     38     48     58     68     78     88\n","row_9       9     19     29     39     49     59     69     79     89\n","row_10     10     20     30     40     50     60     70     80     90\n","26\n","       col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9\n","row_4      4     14     24     34     44     54     64     74     84\n","row_5      5     15     25     35     45     55     65     75     85\n","row_6      6     16     26     36     46     56     66     76     86\n","        col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9\n","row_8       8     18     28     38     48     58     68     78     88\n","row_9       9     19     29     39     49     59     69     79     89\n","row_10     10     20     30     40     50     60     70     80     90\n","col_3    21\n","col_9    81\n","col_4    31\n","Name: row_1, dtype: int64\n","22\n"]}],"source":["print(df)\n","\n","#using the at indexer\n","print(df.at['row_6', 'col_3'])\n","\n","#poision based indexing\n","print(df[3:6])\n","#print(df.iloc[3])\n","print(df.iloc[7:10])\n","print(df.iloc[0, [2, 8, 3]])\n","print(df.iat[1,2])"]},{"cell_type":"markdown","metadata":{"id":"ZF9ylI3uV1mK"},"source":["### **Example13**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_GiuryMpV1mK"},"outputs":[],"source":["Biodata = {'Name': ['Ahmad', 'Ali', 'Omar', 'Hamzah'], 'Age': [28, 23, 35, 31],\n","           'Gender': ['M', 'F', 'M', 'F']\n","           }\n","df = pd.DataFrame(Biodata)\n","\n","df.to_csv('Biodata.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"2KwDGz64V1mK"},"source":["### **Example14**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VkB33KFiV1mK","outputId":"6b25a588-8460-4487-fd1a-66a7b83e0acf"},"outputs":[{"name":"stdout","output_type":"stream","text":["    Name  Height Qualification\n","0  ahmad     180           Msc\n","1    ali     175           Bsc\n","2  osama     170           Phd\n","3  mutaz     185            MA\n","    Name  Height Qualification   Address\n","0  ahmad     180           Msc     Jenin\n","1    ali     175           Bsc    Nablus\n","2  osama     170           Phd  Ramallah\n","3  mutaz     185            MA     Surda\n"]}],"source":["data = {'Name': [\"ahmad\", \"ali\", \"osama\", \"mutaz\"],\n","        'Height': [180, 175, 170, 185],\n","        'Qualification': [\"Msc\", \"Bsc\", \"Phd\", \"MA\"]}\n","\n","df = pd.DataFrame(data)\n","print(df)\n","\n","address = ['Jenin', 'Nablus', 'Ramallah', 'Surda']\n","df['Address'] = address\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"3ODfsNgFV1mK"},"source":["### **Example15**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SPAMTo6fV1mK","outputId":"c1047a8c-ca0c-4ae7-9936-da9625dce98a"},"outputs":[{"name":"stdout","output_type":"stream","text":["    Name  Height Qualification  Age\n","0  ahmad     180           Msc   21\n","1    ali     175           Bsc   23\n","2  osama     170           Phd   24\n","3  mutaz     185            MA   21\n","    Name  Height Qualification  Age\n","0  ahmad     180           Msc   21\n","1    ali     175           Bsc   23\n","2  osama     170           Phd   24\n","3  mutaz     185            MA   21\n","    Name Qualification  Age\n","0  ahmad           Msc   21\n","1    ali           Bsc   23\n","2  osama           Phd   24\n","3  mutaz            MA   21\n"]}],"source":["data = {'Name': [\"ahmad\", \"ali\", \"osama\", \"mutaz\"],\n","        'Height': [180, 175, 170, 185],\n","        'Qualification': [\"Msc\", \"Bsc\", \"Phd\", \"MA\"],\n","        'Age': [21, 23, 24, 21]}\n","\n","df = pd.DataFrame(data)\n","print(df)\n","\n","df1 = df.drop(['Height'], axis=1)\n","print(df)\n","print(df1)"]},{"cell_type":"markdown","metadata":{"id":"sDOcgglFV1mK"},"source":["### **Example14.2**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95Abk_-wV1mK","outputId":"7be3abd9-0771-43bb-ed61-207f534814fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Courses    Fee Duration  Discount\n","0    Spark  22000   30days      1000\n","1  PySpark  25000   50days      2300\n","2   Hadoop  23000   35days      1000\n","3   Python  24000   40days      1200\n","4   Pandas  26000   55days     25000\n","\n","     Courses    Fee Duration  Discount\n","0     Spark  22000   30days      1000\n","1   PySpark  25000   50days      2300\n","2    Hadoop  23000   35days      1000\n","3    Python  24000   40days      1200\n","4    Pandas  26000   55days     25000\n","5  Hyperion  27000   60days      2000\n"]}],"source":["tech = {\n","  'Courses': ['Spark', 'PySpark', 'Hadoop', 'Python', 'Pandas'],\n","  'Fee': [22000, 25000, 23000, 24000, 26000],\n","  'Duration': ['30days', '50days', '35days', '40days', '55days'],\n","  'Discount': [1000, 2300, 1000, 1200, 25000]\n","}\n","\n","df = pd.DataFrame(tech)\n","print(df)\n","\n","entry = ['Hyperion', 27000, '60days', 2000]\n","df.loc[len(df)] = entry\n","print('\\n', df)"]},{"cell_type":"markdown","metadata":{"id":"RaxLkSyGV1mL"},"source":["### **Example16**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PSrSQuy-V1mL","outputId":"ac2c2c8b-d6a2-4e06-ec42-776b07ad184d"},"outputs":[{"name":"stdout","output_type":"stream","text":["    Courses    Fee Duration  Discount\n","r1    Spark  22000   30days      1000\n","r2  PySpark  25000   50days      2300\n","r3   Hadoop  23000   35days      1000\n","r4   Python  24000   40days      1200\n","r5   Pandas  26000   55days     25000\n","   Courses    Fee Duration  Discount\n","r3  Hadoop  23000   35days      1000\n","r4  Python  24000   40days      1200\n","r5  Pandas  26000   55days     25000\n"]}],"source":["techs = {\n","  'Courses': ['Spark', 'PySpark', 'Hadoop', 'Python', 'Pandas'],\n","  'Fee': [22000, 25000, 23000, 24000, 26000],\n","  'Duration': ['30days', '50days', '35days', '40days', '55days'],\n","  'Discount': [1000, 2300, 1000, 1200, 25000]\n","}\n","\n","indexes = ['r1', 'r2', 'r3', 'r4', 'r5']\n","df = pd.DataFrame(techs, index=indexes)\n","print(df)\n","\n","df1 = df.drop(['r1', 'r2']) # df1 = df.drop(index=['r1','r2'])\n","print(df1)"]},{"cell_type":"markdown","metadata":{"id":"NebSUX7bV1mL"},"source":["### **Example17**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6nPUeImOV1mL","outputId":"27869c31-d932-4f4d-830e-1b37d002a229"},"outputs":[{"name":"stdout","output_type":"stream","text":["    Courses    Fee Duration  Discount\n","r1    Spark  22000   30days      1000\n","r2  PySpark  25000   50days      2300\n","r3   Hadoop  23000   35days      1000\n","r4   Python  24000   40days      1200\n","r5   Pandas  26000   55days     25000\n","   Courses    Fee Duration  Discount\n","r1   Spark  22000   30days      1000\n","r3  Hadoop  23000   35days      1000\n","r5  Pandas  26000   55days     25000\n","    Courses    Fee Duration  Discount\n","r2  PySpark  25000   50days      2300\n","r3   Hadoop  23000   35days      1000\n","r4   Python  24000   40days      1200\n","    Courses    Fee Duration  Discount\n","r2  PySpark  25000   50days      2300\n","r3   Hadoop  23000   35days      1000\n"]}],"source":["techs = {\n","  'Courses': ['Spark', 'PySpark', 'Hadoop', 'Python', 'Pandas'],\n","  'Fee': [22000, 25000, 23000, 24000, 26000],\n","  'Duration': ['30days', '50days', '35days', '40days', '55days'],\n","  'Discount': [1000, 2300, 1000, 1200, 25000]\n","}\n","\n","indexes = ['r1', 'r2', 'r3', 'r4', 'r5']\n","df = pd.DataFrame(techs, index=indexes)\n","print(df)\n","\n","df1 = df.drop(df.index[[1,3]])\n","print(df1)\n","\n","df.drop(df.index[0], inplace=True)\n","df.drop(df.index[-1], inplace=True)\n","print(df)\n","\n","df1 = df.drop(df.index[2:])\n","print(df1)"]},{"cell_type":"markdown","metadata":{"id":"MsdNbyplV1mL"},"source":["### **Example18**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ShvUWUh7V1mL","outputId":"15dd9d7f-e0d0-4037-9dea-c5fe58cb0835"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Courses    Fee Duration  Discount\n","0    Spark  22000   30days      1000\n","1  PySpark  25000   50days      2300\n","2   Hadoop  23000   35days      1000\n","3   Python  24000   40days      1200\n","4   Pandas  26000   55days     25000 \n","\n","\n","   Courses    Fee Duration  Discount\n","1  PySpark  25000   50days      2300\n","2   Hadoop  23000   35days      1000\n","3   Python  24000   40days      1200\n","4   Pandas  26000   55days     25000 \n","\n","    Courses    Fee Duration  Discount\n","1  PySpark  25000   50days      2300\n","2   Hadoop  23000   35days      1000\n","4   Pandas  26000   55days     25000 \n","\n","   Courses    Fee Duration  Discount\n","2  Hadoop  23000   35days      1000\n","3  Python  24000   40days      1200\n","4  Pandas  26000   55days     25000\n"]}],"source":["techs = {\n","  'Courses': ['Spark', 'PySpark', 'Hadoop', 'Python', 'Pandas'],\n","  'Fee': [22000, 25000, 23000, 24000, 26000],\n","  'Duration': ['30days', '50days', '35days', '40days', '55days'],\n","  'Discount': [1000, 2300, 1000, 1200, 25000]\n","}\n","\n","df = pd.DataFrame(techs)\n","print(df, '\\n\\n')\n","df1 = df.drop(0)\n","df3 = df.drop([0, 3])\n","df4 = df.drop(range(0,2))\n","print(df1, '\\n\\n', df3, '\\n\\n', df4)"]},{"cell_type":"markdown","metadata":{"id":"o2SfiKB8V1mL"},"source":["### **Example19**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MyC_XxyTV1mL","outputId":"ba246205-18e5-462e-af6b-4f226d6e2c22"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Courses    Fee Duration  Discount\n","0    Spark  22000   30days      1000\n","1  PySpark  25000   50days      2300\n","2   Hadoop  23000   35days      1000\n","3   Python  24000   40days      1200\n","4   Pandas  26000   55days     25000 \n","\n","\n","  Courses    Fee Duration  Discount\n","0   Spark  22000   30days      1000\n","2  Hadoop  23000   35days      1000\n","  Courses    Fee Duration  Discount\n","0   Spark  22000   30days      1000\n","2  Hadoop  23000   35days      1000\n"]}],"source":["techs = {\n","  'Courses': ['Spark', 'PySpark', 'Hadoop', 'Python', 'Pandas'],\n","  'Fee': [22000, 25000, 23000, 24000, 26000],\n","  'Duration': ['30days', '50days', '35days', '40days', '55days'],\n","  'Discount': [1000, 2300, 1000, 1200, 25000]\n","}\n","\n","df = pd.DataFrame(techs)\n","print(df, '\\n\\n')\n","# df.drop(df[df['Fee'] >= 24000].index, inplace=True)\n","# print(df)\n","\n","df1 = df[df['Fee'] < 24000]\n","print(df1)\n","\n","df2 = df.loc[df['Fee'] < 24000]\n","print(df2)\n"]},{"cell_type":"markdown","metadata":{"id":"IBBJBCOlV1mL"},"source":["### **Example20**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2mITX_MV1mL","outputId":"668f605d-e054-4cab-a4ff-e7ed7b586ecb"},"outputs":[{"name":"stdout","output_type":"stream","text":["    A   B   C   D\n","0  A0  B0  C0  D0\n","1  A1  B1  C1  D1\n","2  A2  B2  C2  D2\n","3  A3  B3  C3  D3\n","0  A4  B4  C4  D4\n","1  A5  B5  C5  D5\n","2  A6  B6  C6  D6\n","3  A7  B7  C7  D7\n"]}],"source":["df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n","                    'B': ['B0', 'B1', 'B2', 'B3'],\n","                    'C': ['C0', 'C1', 'C2', 'C3'],\n","                    'D': ['D0', 'D1', 'D2', 'D3']})\n","\n","df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n","                    'B': ['B4', 'B5', 'B6', 'B7'],\n","                    'C': ['C4', 'C5', 'C6', 'C7'],\n","                    'D': ['D4', 'D5', 'D6', 'D7']})\n","\n","result = pd.concat([df1, df2])\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"a_Z1cVv4V1mM"},"source":["<hr>"]},{"cell_type":"markdown","metadata":{"id":"3wFAdb33V1mM"},"source":["<a name=\"Tasks\"></a>\n","## **Tasks**"]},{"cell_type":"markdown","metadata":{"id":"ggRl6i2cV1mM"},"source":["#### **Task1**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q0GIAj0MV1mM","outputId":"11ec892d-1337-4216-fdc2-a5372cf7d27f"},"outputs":[{"name":"stdout","output_type":"stream","text":["       col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9\n","row_1      1     11     21     31     41     51     61     71     81\n","row_2      2     12     22     32     42     52     62     72     82\n","row_3      3     13     23     33     43     53     63     73     83\n","row_4      4     14     24     34     44     54     64     74     84\n"]}],"source":["df = pd.DataFrame({'col_1': list(range(1, 11)),\n","                   'col_2': list(range(11, 21)),\n","                   'col_3': list(range(21, 31)),\n","                   'col_4': list(range(31, 41)),\n","                   'col_5': list(range(41, 51)),\n","                   'col_6': list(range(51, 61)),\n","                   'col_7': list(range(61, 71)),\n","                   'col_8': list(range(71, 81)),\n","                   'col_9': list(range(81, 91))})\n","\n","df.index = ['row_1', 'row_2', 'row_3', 'row_4', 'row_5',\n","            'row_6', 'row_7', 'row_8', 'row_9', 'row_10']\n","\n","selected_rows = df.loc['row_1':'row_4']\n","print(selected_rows)"]},{"cell_type":"markdown","metadata":{"id":"fVLyQfXDV1mM"},"source":["Using the range from row_1 to row_4 using ':', the first 4 rows were printed."]},{"cell_type":"markdown","metadata":{"id":"jHuANUirV1mM"},"source":["#### **Task2**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oC8OU24rV1mM","outputId":"0d9bab6b-9258-4766-c8ca-a9a5d754c9d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["col_5    50\n","col_6    60\n","col_7    70\n","Name: row_10, dtype: int64\n"]}],"source":["print(df.iloc[-1].loc['col_5':'col_7'])"]},{"cell_type":"markdown","metadata":{"id":"YnpEpb8FV1mM"},"source":["Using iloc[-1] the last row was obtained, then using loc['col_5':'col_7'} the columns in the range 5-7 were obtained. and so the last row with those columns was printed."]},{"cell_type":"markdown","metadata":{"id":"T1MGt6irV1mM"},"source":["#### **Task3**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Djcxw5ZlV1mN","outputId":"8d06bab3-179c-4cfa-ecdf-50c1d096ac2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["       col_5  col_6  col_7  col_8  col_9\n","row_1     41     51     61     71     81\n","row_8     48     58     68     78     88\n"]}],"source":["print(df.iloc[[0,7], 4:9])\n"]},{"cell_type":"markdown","metadata":{"id":"NFKSyCvZV1mN"},"source":["With iloc, both rows and columns can be specified as parameters (respectively). First, rows 1 and 8 were specified, then columns in the range 5-9 were specified. The result was printed."]},{"cell_type":"markdown","metadata":{"id":"_rLWgK8tV1mO"},"source":["#### **Task4**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CWHzouJPV1mO","outputId":"c23064b2-41a1-4f94-b6ff-4ab249d77b48"},"outputs":[{"name":"stdout","output_type":"stream","text":["        col_1  col_3  col_7\n","row_1       1     21     61\n","row_2       2     22     62\n","row_3       3     23     63\n","row_4       4     24     64\n","row_5       5     25     65\n","row_6       6     26     66\n","row_7       7     27     67\n","row_8       8     28     68\n","row_9       9     29     69\n","row_10     10     30     70\n"]}],"source":["print(df.iloc[:, [0, 2, 6]])\n"]},{"cell_type":"markdown","metadata":{"id":"T1AgmbNXV1mO"},"source":["Using the ':' operator, all rows were selected, then columns 0, 2, 6 were specified. The result was printed."]},{"cell_type":"markdown","metadata":{"id":"MN-aqCqqV1mO"},"source":["#### **Task5**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TAyxs8a2V1mO","outputId":"092cc08d-018c-407f-bf27-19df22d76cd2"},"outputs":[{"name":"stdout","output_type":"stream","text":["       col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9\n","row_1      1     11     21     31     41     51     61     71     81\n","row_2      2     12     22     32     42     52     62     72     82\n","row_3      3     13     23     33     43     53     63     73     83\n","row_4      4     14     24     34     44     54     64     74     84\n","row_5      5     15     25     35     45     55     65     75     85\n"]}],"source":["print(df[df['col_2'] <= 15])\n"]},{"cell_type":"markdown","metadata":{"id":"9RmPa13nV1mO"},"source":["The inner df returns true for all rows where the condition is met. Then the outer df filters out the falsy rows, then the result is printed."]},{"cell_type":"markdown","metadata":{"id":"1OVo9UIqV1mO"},"source":["#### **Task6**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UgFtB-aeV1mO","outputId":"060e894e-76b3-4be4-bafb-e34352729afc"},"outputs":[{"name":"stdout","output_type":"stream","text":["        col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9\n","row_6       6     16     26     36     46     56     66     76     86\n","row_7       7     17     27     37     47     57     67     77     87\n","row_8       8     18     28     38     48     58     68     78     88\n","row_10     10     20     30     40     50     60     70     80     90\n"]}],"source":["print(df[(df['col_2'] > 15) & (df['col_2'] != 19)])\n"]},{"cell_type":"markdown","metadata":{"id":"b6luohSGV1mP"},"source":["Same as the previous task, but here the condition consists of two conditions with an 'and' (&) operator between them."]},{"cell_type":"markdown","metadata":{"id":"nC_3eOVOV1mP"},"source":["#### **Task7**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"He5DlOzIV1mP"},"outputs":[],"source":["Biodata = {'Name': ['Ahmad', 'Ali', 'Omar', 'Hamzah'], 'Age': [28, 23, 35, 31],\n","           'Gender': ['M', 'F', 'M', 'F']\n","           }\n","df = pd.DataFrame(Biodata)\n","\n","df.to_csv('Biodata_tabular.csv', sep='\\t', index=False)"]},{"cell_type":"markdown","metadata":{"id":"9lUkgDAOV1mP"},"source":["Using sep='\\t', the data was saved to Bidodata_tabular.csv with tab separators instead of a comma."]},{"cell_type":"markdown","metadata":{"id":"0Bm-RKGBV1mP"},"source":["#### **Task8**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_xrwNTbIV1mP","outputId":"dfd9c388-687a-4823-a50c-06e631085dd8"},"outputs":[{"name":"stdout","output_type":"stream","text":["    Name  Height Qualification   Address  Age\n","0  ahmad     180           Msc     Jenin   21\n","1    ali     175           Bsc    Nablus   23\n","2  osama     170           Phd  Ramallah   24\n","3  mutaz     185            MA     Surda   21\n"]}],"source":["data = {'Name': [\"ahmad\", \"ali\", \"osama\", \"mutaz\"],\n","        'Height': [180, 175, 170, 185],\n","        'Qualification': [\"Msc\", \"Bsc\", \"Phd\", \"MA\"]}\n","\n","df = pd.DataFrame(data)\n","\n","address = ['Jenin', 'Nablus', 'Ramallah', 'Surda']\n","df['Address'] = address\n","\n","age = [21, 23, 24, 21]\n","df['Age'] = age\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"-amok0bDV1mP"},"source":["New columns (lists) 'Address' and 'Age' were added to the original DataFrame, by using each as an index and equating it to the list."]},{"cell_type":"markdown","metadata":{"id":"LNxMEg1HV1mP"},"source":["#### **Task9**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"httekpTJV1mP","outputId":"998ed394-6296-4ce3-f436-78221d58c922"},"outputs":[{"name":"stdout","output_type":"stream","text":["    Name  Height Qualification  Age\n","0  ahmad     180           Msc   21\n","1    ali     175           Bsc   23\n","2  osama     170           Phd   24\n","3  mutaz     185            MA   21\n","    Name Qualification\n","0  ahmad           Msc\n","1    ali           Bsc\n","2  osama           Phd\n","3  mutaz            MA\n"]}],"source":["data = {'Name': [\"ahmad\", \"ali\", \"osama\", \"mutaz\"],\n","        'Height': [180, 175, 170, 185],\n","        'Qualification': [\"Msc\", \"Bsc\", \"Phd\", \"MA\"],\n","        'Age': [21, 23, 24, 21]}\n","\n","df = pd.DataFrame(data)\n","print(df)\n","\n","df.drop(['Height', 'Age'], axis=1, inplace=True)\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"ZjkOHD4IV1mP"},"source":["By using ['Height', 'Age'] as the list-index, specifiying the axis to 1 (columns), and using inplace=True, the two columns were dropped from the original DataFrame in-place."]},{"cell_type":"markdown","metadata":{"id":"DiA1SaAGV1mP"},"source":["#### **Task10**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xssnyax6V1mQ","outputId":"7b98d92a-018e-47b5-cf93-381e3d493bcb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Before:\n","    Courses    Fee Duration  Discount\n","0    Spark  22000   30days      1000\n","1  PySpark  25000   50days      2300\n","2   Hadoop  23000   35days      1000\n","3   Python  24000   40days      1200\n","4   Pandas  26000   55days     25000\n","\n","After:\n","     Courses    Fee Duration  Discount\n","0     Spark  22000   30days      1000\n","1  Hyperion  27000   60days      2000\n","2   PySpark  25000   50days      2300\n","3    Hadoop  23000   35days      1000\n","4    Python  24000   40days      1200\n","5    Pandas  26000   55days     25000\n"]}],"source":["tech = {\n","  'Courses': ['Spark', 'PySpark', 'Hadoop', 'Python', 'Pandas'],\n","  'Fee': [22000, 25000, 23000, 24000, 26000],\n","  'Duration': ['30days', '50days', '35days', '40days', '55days'],\n","  'Discount': [1000, 2300, 1000, 1200, 25000]\n","}\n","\n","df = pd.DataFrame(tech)\n","print('Before:\\n',df)\n","\n","list1 = ['Hyperion', 27000, '60days', 2000]\n","#df.loc[len(df)] = list1\n","# df.iloc[1] = list1\n","df_temp1 = df.iloc[0:2].copy()\n","df_temp2 = df.iloc[1:].copy()\n","df_temp1.iloc[1] = list1\n","df = pd.concat([df_temp1, df_temp2])\n","df.index = range(len(df))\n","print('\\nAfter:\\n', df)"]},{"cell_type":"markdown","metadata":{"id":"8zbMoXjAV1mQ"},"source":["To add the new row into the second position, the DataFrame was split into two, and each part was copied to avoid changing the rows in the original DataFrame. Then the new row was added in the last position in the first part, then the two parts were concatenated, and the result was printed. The index of the df was reset because otherwise the rows will be [0,1,1,2,3,4]."]},{"cell_type":"markdown","metadata":{"id":"0RT1OGN-V1mQ"},"source":["#### **Task11**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KPzoA4emV1mQ","outputId":"c81122d6-54e0-46e6-8a9a-842685a9dd6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Before:\n","    Courses    Fee Duration  Discount\n","0    Spark  22000   30days      1000\n","1  PySpark  25000   50days      2300\n","2   Hadoop  23000   35days      1000\n","3   Python  24000   40days      1200\n","4   Pandas  26000   55days     25000\n","\n","After:\n","   Courses    Fee Duration  Discount\n","0   Spark  22000   30days      1000\n","1  Hadoop  23000   35days      1000\n","2  Python  24000   40days      1200\n","3  Pandas  26000   55days     25000\n"]}],"source":["techs = {\n","  'Courses': ['Spark', 'PySpark', 'Hadoop', 'Python', 'Pandas'],\n","  'Fee': [22000, 25000, 23000, 24000, 26000],\n","  'Duration': ['30days', '50days', '35days', '40days', '55days'],\n","  'Discount': [1000, 2300, 1000, 1200, 25000]\n","}\n","\n","df = pd.DataFrame(techs)\n","print('Before:\\n', df)\n","df1 = df.drop(df[(df['Fee'] >= 22000) & (df['Discount'] == 2300)].index)\n","df1.index = range(len(df1))\n","print('\\nAfter:\\n', df1)\n","df1.to_csv('task11.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"gZt-FngHV1mS"},"source":["The index of rows resulting from the conditional filtering were returned by using .index after the conditions so that they get droped (deleted) from the DataFrame."]},{"cell_type":"markdown","metadata":{"id":"JAL5_sgHV1mS"},"source":["#### **Task12**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ae93PptTV1mS","outputId":"11da33df-5a79-4862-e198-f1fa7b7d45ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Courses    Fee Duration  Discount\n","0    Spark  22000   30days    1000.0\n","1  PySpark  25000   50days    2300.0\n","2   Hadoop  23000   35days       NaN\n","3   Python  24000   40days    1200.0\n","4   Pandas  26000   55days       NaN \n","\n","\n","   Courses    Fee Duration  Discount\n","0    Spark  22000   30days    1000.0\n","1  PySpark  25000   50days    2300.0\n","3   Python  24000   40days    1200.0\n"]}],"source":["techs = {\n","  'Courses': ['Spark', 'PySpark', 'Hadoop', 'Python', 'Pandas'],\n","  'Fee': [22000, 25000, 23000, 24000, 26000],\n","  'Duration': ['30days', '50days', '35days', '40days', '55days'],\n","  'Discount': [1000, 2300, None, 1200, None]\n","}\n","\n","df = pd.DataFrame(techs)\n","print(df, '\\n\\n')\n","\n","# Drop those rows\n","df1 = df.drop(df[df.isnull().any(axis=1)].index)\n","print(df1)\n"]},{"cell_type":"markdown","metadata":{"id":"Z1-t8RZ6V1mS"},"source":["isnull() was used to determine where the None/NaN values are in the DataFrame, then any(axis)=1 was used to return the rows where any of the values are None/NaN. Then their index was used to delete them using drop()."]},{"cell_type":"markdown","metadata":{"id":"pDyyxnmrV1mS"},"source":["#### **Task13**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-3XuoTiV1mS","outputId":"a4fe412b-6c37-410f-9137-d9e7e32839a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Courses    Fee Duration  Discount\n","0    Spark  22000   30days      1000\n","1  PySpark  25000   50days      2300\n","2   Hadoop  23000   35days      1000\n","3   Python  24000   40days      1200\n","4   Pandas  26000   55days     25000 \n","\n","\n","   Courses    Fee Duration  Discount\n","1  PySpark  25000   50days      2300\n","3   Python  24000   40days      1200\n","4   Pandas  26000   55days     25000\n"]}],"source":["techs = {\n","  'Courses': ['Spark', 'PySpark', 'Hadoop', 'Python', 'Pandas'],\n","  'Fee': [22000, 25000, 23000, 24000, 26000],\n","  'Duration': ['30days', '50days', '35days', '40days', '55days'],\n","  'Discount': [1000, 2300, 1000, 1200, 25000]\n","}\n","\n","df = pd.DataFrame(techs)\n","print(df, '\\n\\n')\n","df1 = df.drop(df[(df['Courses'] == 'Spark') | (df['Courses'] == 'Hadoop')].index)\n","print(df1)"]},{"cell_type":"markdown","metadata":{"id":"9WC_z-WyV1mT"},"source":["Using two conditions to filter the DataFrame using 'or' (|) operator between them, then the rows indecies were returned and used to drop them from the DataFrame."]},{"cell_type":"markdown","metadata":{"id":"aoAVuFpYV1mT"},"source":["#### **Task14**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SOQpFuvZV1mT","outputId":"1e909bea-15fe-43bb-ca80-1aa184f4593a"},"outputs":[{"name":"stdout","output_type":"stream","text":["    A   B   C   D   A   B   C   D\n","0  A0  B0  C0  D0  A4  B4  C4  D4\n","1  A1  B1  C1  D1  A5  B5  C5  D5\n","2  A2  B2  C2  D2  A6  B6  C6  D6\n","3  A3  B3  C3  D3  A7  B7  C7  D7\n"]}],"source":["df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n","                    'B': ['B0', 'B1', 'B2', 'B3'],\n","                    'C': ['C0', 'C1', 'C2', 'C3'],\n","                    'D': ['D0', 'D1', 'D2', 'D3']})\n","\n","df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n","                    'B': ['B4', 'B5', 'B6', 'B7'],\n","                    'C': ['C4', 'C5', 'C6', 'C7'],\n","                    'D': ['D4', 'D5', 'D6', 'D7']})\n","\n","result = pd.concat([df1, df2], axis=1)\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"NV4EESDvV1mT"},"source":["By specifying the paramter axis to equal 1, the concatenation was done column-wise instead of row-wise."]},{"cell_type":"markdown","metadata":{"id":"jBmlspV9V1mT"},"source":["#### **Task15**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EQYZ-2UgV1mT","outputId":"f511b4d5-d4b8-40bf-84b4-218415893baf"},"outputs":[{"name":"stdout","output_type":"stream","text":["    A   B   C   D\n","0  A0  B0  C0  D0\n","1  A1  B1  C1  D1\n","2  A2  B2  C2  D2\n","3  A3  B3  C3  D3 \n","\n","     A   B   C   D\n","0  A4  B0  C0  D1\n","1  A5  C2  C0  D2\n","2  A6  B0  B2  D6\n","3  A7  B1  C3  D7\n"]}],"source":["df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n","                    'B': ['B0', 'B1', 'B2', 'B3'],\n","                    'C': ['C0', 'C1', 'C2', 'C3'],\n","                    'D': ['D0', 'D1', 'D2', 'D3']})\n","\n","df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n","                    'B': ['B0', 'C2', 'B0', 'B1'],\n","                    'C': ['C0', 'C0', 'B2', 'C3'],\n","                    'D': ['D1', 'D2', 'D6', 'D7']})\n","\n","print(df1, '\\n\\n', df2)"]},{"cell_type":"markdown","metadata":{"id":"WcDhbaizV1mT"},"source":["- ####  **Part1 - Inner Join**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HcX3ID53V1mT","outputId":"8da5621c-6b95-4c8e-f9bd-d2d9882e2969"},"outputs":[{"name":"stdout","output_type":"stream","text":["  A_x   B C_x D_x A_y C_y D_y\n","0  A0  B0  C0  D0  A4  C0  D1\n","1  A0  B0  C0  D0  A6  B2  D6\n","2  A1  B1  C1  D1  A7  C3  D7\n"]}],"source":["df = pd.merge(df1, df2, on='B')\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"ZC7IkPvNV1mT"},"source":["Performing inner join on both DFs on column B results in all rows where the values in column B are the same in both DFs."]},{"cell_type":"markdown","metadata":{"id":"4n1MQwsYV1mU"},"source":["- ####  **Part2 - Left Outer Join**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qmpZOS5KV1mU","outputId":"31d7288e-ac2b-4d98-e80b-b89602cc7cc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["  A_x B_x   C D_x  A_y  B_y  D_y\n","0  A0  B0  C0  D0   A4   B0   D1\n","1  A0  B0  C0  D0   A5   C2   D2\n","2  A1  B1  C1  D1  NaN  NaN  NaN\n","3  A2  B2  C2  D2  NaN  NaN  NaN\n","4  A3  B3  C3  D3   A7   B1   D7\n"]}],"source":["df = df1.merge(df2, on='C', how='left')\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"c8suQDCBWAns"},"source":["  Performing left outer join on column C results in merging the first DF with the rows from the second DF where the values of C are common, based on the values of C in the first DF."]},{"cell_type":"markdown","metadata":{"id":"oR1ICb-gV1mU"},"source":["- ####  **Part3 - Right Outer Join**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3xdPL6dXV1mU","outputId":"7b453877-2033-4e29-8ab0-d02520db7a8a"},"outputs":[{"name":"stdout","output_type":"stream","text":["   A_x  B_x   C  D_x A_y B_y D_y\n","0   A0   B0  C0   D0  A4  B0  D1\n","1   A0   B0  C0   D0  A5  C2  D2\n","2  NaN  NaN  B2  NaN  A6  B0  D6\n","3   A3   B3  C3   D3  A7  B1  D7\n"]}],"source":["df = df1.merge(df2, on='C', how='right')\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"6XhvalBkdGKD"},"source":["  Performing right outer join on column C results in merging the second DF with the rows from the first DF where the values of C are common, based on the values of C in the second DF."]},{"cell_type":"markdown","metadata":{"id":"cne35My5V1mU"},"source":["- ####  **Part4 - Full Outer Join**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dWYJe1PhV1mU","outputId":"473c62b8-adb3-4655-fc7a-ed2c301c91e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["    A   B   C   D\n","0  A0  B0  C0  D0\n","1  A1  B1  C1  D1\n","2  A2  B2  C2  D2\n","3  A3  B3  C3  D3\n","4  A4  B0  C0  D1\n","5  A5  C2  C0  D2\n","6  A6  B0  B2  D6\n","7  A7  B1  C3  D7\n"]}],"source":["df = pd.merge(df1, df2, how='outer')\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"MND15JwQdGKD"},"source":["By specifying how='outer', all rows from both DFs are merged."]},{"cell_type":"markdown","metadata":{"id":"9AgB0RErV1mU"},"source":["- ####  **Part5 - Left Anti-Join**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BXkq56V9V1mU","outputId":"091f6588-dfa7-40a5-ba85-9767396dfa0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["    A   B   C   D\n","2  A2  B2  C2  D2\n","3  A3  B3  C3  D3\n"]}],"source":["df3 = df1.merge(df2, on='B', how='left', indicator=True)\n","df = df3.loc[df3['_merge'] == 'left_only', 'B']\n","d = df1[df1['B'].isin(df)]\n","print(d)"]},{"cell_type":"markdown","metadata":{"id":"GoYhtcMydGKE"},"source":["By extracing the rows where values of B from the first DF are not in the second DF, the left anti-join is performed."]},{"cell_type":"markdown","metadata":{"id":"ZLq6pTczV1mU"},"source":["- ####  **Part6 - Right Anti-Join**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4zSZ2B3yV1mU","outputId":"0b72dfe8-812b-4f25-aae5-bac628f9e148"},"outputs":[{"name":"stdout","output_type":"stream","text":["    A   B   C   D\n","2  A6  B0  B2  D6\n"]}],"source":["df3 = df1.merge(df2, on='C', how='right', indicator=True)\n","df = df3.loc[df3['_merge'] == 'right_only', 'C']\n","d = df2[df2['C'].isin(df)]\n","print(d)"]},{"cell_type":"markdown","metadata":{"id":"Mr3kKwi7dGKF"},"source":["By extracing the rows where values of C from the first DF are not in the second DF, the left anti-join is performed."]},{"cell_type":"markdown","metadata":{"id":"xNu8bM-jV1mU"},"source":["- ####  **Part7 - Full Anti-Join**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUbQxl9HV1mV","outputId":"49a99d8a-8f76-4c18-cc92-b9bf1d03e0eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["   A_x   B  C_x  D_x  A_y  C_y  D_y      _merge\n","3   A2  B2   C2   D2  NaN  NaN  NaN   left_only\n","4   A3  B3   C3   D3  NaN  NaN  NaN   left_only\n","5  NaN  C2  NaN  NaN   A5   C0   D2  right_only\n"]}],"source":["df3 = df1.merge(df2, on='B', how='outer', indicator=True)\n","df = df3.loc[df3['_merge'] == 'both', 'B']\n","d = df3[~df3['B'].isin(df)]\n","print(d)"]},{"cell_type":"markdown","metadata":{"id":"TNvcoChfdGKF"},"source":["By extracting the rows where values of B are common in both DFs, then filtering them out and keeping the rest, the full anti-join is performed."]},{"cell_type":"markdown","metadata":{"id":"gkmk5dYyV1mV"},"source":["- ####  **Part8 - Merging on Different Column Names**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JxDQcDmCV1mV","outputId":"f1025148-88ac-499f-f5f1-142e8d34fdbf"},"outputs":[{"name":"stdout","output_type":"stream","text":["  A_x B_x C_x D_x A_y B_y C_y D_y\n","0  A2  B2  C2  D2  A5  C2  C0  D2\n"]}],"source":["df = df1.merge(df2, left_on='C', right_on='B')\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"85ZL8M_bdGKG"},"source":["This merge returns the rows where the common values between C from DF1, and B from DF2 are present."]},{"cell_type":"markdown","metadata":{"id":"3ThopTJmV1mV"},"source":["- ####  **Part9 - Merging on Multiple Columns**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8V76EunTV1mV","outputId":"eb03aad4-4330-4f4d-82b4-f1acc01bb28e"},"outputs":[{"name":"stdout","output_type":"stream","text":["  A_x   B   C D_x A_y D_y\n","0  A0  B0  C0  D0  A4  D1\n"]}],"source":["df = df1.merge(df2, on=['B', 'C'])\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"s7G8QNiPdGKG"},"source":["This merge returns the rows where the each column in both DFs has the same value. So, B in both DFs has B0, and C in both DFs has C0, so that row is returned."]},{"cell_type":"markdown","metadata":{"id":"BNHFwHhjV1mV"},"source":["<hr>"]},{"cell_type":"markdown","metadata":{"id":"0Y4MsTVUV1mV"},"source":["#### **Task16**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XLCUutN0V1mW","outputId":"3fead561-ad93-4067-8232-750f5e3ca41c"},"outputs":[{"name":"stdout","output_type":"stream","text":["    A B_x   C   D  B_y\n","0  A0  B0  C0  D0  NaN\n","1  A1  B1  C1  D1  NaN\n","2  A2  B2  C2  D2   C2\n","3  A3  B3  C3  D3  NaN\n"]}],"source":["df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n","                    'B': ['B0', 'B1', 'B2', 'B3'],\n","                    'C': ['C0', 'C1', 'C2', 'C3'],\n","                    'D': ['D0', 'D1', 'D2', 'D3']})\n","\n","df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n","                    'B': ['B0', 'C2', 'B0', 'B1'],\n","                    'C': ['C0', 'C0', 'B2', 'C3'],\n","                    'D': ['D1', 'D2', 'D6', 'D7']})\n","\n","df = df1.merge(df2['B'], left_on='C', right_on='B', how='left')\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"uiHHxhqKdGKH"},"source":["By merging different columns, but selecting only column B from df2 using df2['B'], then specifiying the columns C and B from DF1 and DF2 respectively, we can perform a left outer join with all columns from DF1 and only column B from DF2."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}